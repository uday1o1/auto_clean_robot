{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UsNm-Fxdulsz",
    "outputId": "11649de8-1d4d-4965-8811-9ab414aff20e"
   },
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"LpIOo51TriziCYxqzIZw\")\n",
    "project = rf.workspace(\"test-hmoom\").project(\"cleaning_bot_dataset_2.0\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"voc\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8TBkr-NRPd-Z"
   },
   "source": [
    "from google.colab import drive\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import requests\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw2l8x0W4I_H",
    "outputId": "2afb1d38-5c8b-4e12-fd72-448d1ad04328"
   },
   "source": [
    "def rename_folder(folder_path, new_name):\n",
    "    # Get the directory containing the folder\n",
    "    parent_dir = os.path.dirname(folder_path)\n",
    "\n",
    "    # Create the new path with the new folder name\n",
    "    new_folder_path = os.path.join(parent_dir, new_name)\n",
    "\n",
    "    # Rename the folder\n",
    "    os.rename(folder_path, new_folder_path)\n",
    "\n",
    "    print(f\"Folder renamed from {folder_path} to {new_folder_path}\")\n",
    "\n",
    "# Find all matching folders using glob function\n",
    "folder_paths = glob('/content/cleaning_bot_dataset_2.0-*')\n",
    "\n",
    "if folder_paths:\n",
    "    folder_path = folder_paths[0]  # Use the first match\n",
    "    new_folder_name = 'cleaning_bot_object_dataset'  # New folder name\n",
    "    rename_folder(folder_path, new_folder_name)\n",
    "else:\n",
    "    print(\"No matching folders found.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5VFTngnsyvD"
   },
   "source": [
    "splitting dataset into separate images and xml folders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lNkO3mPs3OR",
    "outputId": "efe71d95-5d87-4bb8-adae-24de993c7756"
   },
   "source": [
    "def move_files_by_extension(source_directory, target_directory, file_extension):\n",
    "    # Ensure the target directory exists (create it if it doesn't)\n",
    "    os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "    # Walk through the source directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            # Check if the file has the specified extension\n",
    "            if file.endswith(file_extension):\n",
    "                # Create full path for source and destination\n",
    "                source_path = os.path.join(root, file)\n",
    "                target_path = os.path.join(target_directory, file)\n",
    "\n",
    "                # Move the file\n",
    "                shutil.move(source_path, target_path)\n",
    "                print(f\"Moved: {source_path} to {target_path}\")\n",
    "\n",
    "def organize_files(folder_name):\n",
    "    # Define source and target directories based on the folder name\n",
    "    source_directory = os.path.join(\"/content/cleaning_bot_object_dataset/\", folder_name)\n",
    "    xml_target_directory = os.path.join(source_directory, \"xmls\")\n",
    "    images_target_directory = os.path.join(source_directory, \"images\")\n",
    "\n",
    "    # Create target directories if they don't exist\n",
    "    os.makedirs(xml_target_directory, exist_ok=True)\n",
    "    os.makedirs(images_target_directory, exist_ok=True)\n",
    "\n",
    "    # Move XML files\n",
    "    move_files_by_extension(source_directory, xml_target_directory, \".xml\")\n",
    "\n",
    "    # Move JPG files\n",
    "    move_files_by_extension(source_directory, images_target_directory, \".jpg\")\n",
    "\n",
    "organize_files(\"test\")\n",
    "organize_files(\"train\")\n",
    "organize_files(\"valid\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtGvXf63A4ey",
    "outputId": "13a2f672-40db-4904-f9d1-9f7b9bc35e8f"
   },
   "source": [
    "# Define the source directories\n",
    "source_dirs = ['/content/cleaning_bot_object_dataset/train', '/content/cleaning_bot_object_dataset/valid', '/content/cleaning_bot_object_dataset/test']\n",
    "\n",
    "# Define the destination directory\n",
    "destination_dir = '/content/cleaning_bot_object_dataset'\n",
    "xml_dest_dir = os.path.join(destination_dir, 'xmls')\n",
    "jpg_dest_dir = os.path.join(destination_dir, 'images')\n",
    "\n",
    "# Create the destination directories if they do not exist\n",
    "os.makedirs(xml_dest_dir, exist_ok=True)\n",
    "os.makedirs(jpg_dest_dir, exist_ok=True)\n",
    "\n",
    "# Copy XML and JPG files from source directories to destination directories\n",
    "for src_dir in source_dirs:\n",
    "    xml_src_dir = os.path.join(src_dir, 'xmls')\n",
    "    jpg_src_dir = os.path.join(src_dir, 'images')\n",
    "\n",
    "    # Copy XML files\n",
    "    for filename in os.listdir(xml_src_dir):\n",
    "        src_file = os.path.join(xml_src_dir, filename)\n",
    "        dest_file = os.path.join(xml_dest_dir, filename)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "    # Copy JPG files\n",
    "    for filename in os.listdir(jpg_src_dir):\n",
    "        src_file = os.path.join(jpg_src_dir, filename)\n",
    "        dest_file = os.path.join(jpg_dest_dir, filename)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "print(\"Files have been successfully combined.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gYhPdjM3Dv5Q"
   },
   "source": [
    "def delete_folder(folder_path):\n",
    "\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove the folder and all its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' and all its contents have been deleted.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8tdRwrkD4hE",
    "outputId": "d63406d3-defa-410d-859f-03c22d980b6a"
   },
   "source": [
    "folder_to_delete = '/content/cleaning_bot_object_dataset/train'\n",
    "delete_folder(folder_to_delete)\n",
    "\n",
    "folder_to_delete = '/content/cleaning_bot_object_dataset/valid'\n",
    "delete_folder(folder_to_delete)\n",
    "\n",
    "folder_to_delete = '/content/cleaning_bot_object_dataset/test'\n",
    "delete_folder(folder_to_delete)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORP1oOW-Ctm6",
    "outputId": "5f284bc4-8a24-45ea-a7b6-aaa22769412a"
   },
   "source": [
    "def count_files_in_folder(folder_path):\n",
    "    # List all files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    return len(files)\n",
    "\n",
    "folder_path = '/content/cleaning_bot_object_dataset/xmls'\n",
    "file_count = count_files_in_folder(folder_path)\n",
    "print(f\"Number of files in '{folder_path}': {file_count}\")\n",
    "\n",
    "folder_path = '/content/cleaning_bot_object_dataset/images'\n",
    "file_count = count_files_in_folder(folder_path)\n",
    "print(f\"Number of files in '{folder_path}': {file_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDJvRvLn4wZo",
    "outputId": "2d1172ce-f19d-4585-fef7-3cc9d59d2559"
   },
   "source": [
    "# Mount your Google Drive\n",
    "drive.mount('/content/drive')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "235rK3EmvzsR",
    "outputId": "35f37287-6095-45d9-9132-75587ee92174"
   },
   "source": [
    "# Define the path to the zip file and the target directory\n",
    "zip_file_path = '/content/drive/MyDrive/colab_notebooks/cleaning_bot/models/best_model.zip'  # zip file path\n",
    "target_directory = '/content/cleaning_bot_object_dataset'  # target directory\n",
    "\n",
    "# Create the target directory if it does not exist\n",
    "os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(target_directory)\n",
    "\n",
    "print(f'Unzipped {zip_file_path} to {target_directory}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MCRfkmh3OYw0"
   },
   "source": [
    "# Path to your .keras model file in Google Drive\n",
    "model_path = '/content/cleaning_bot_object_dataset/content/models/best_model.keras'\n",
    "\n",
    "# Load the model from Google Drive\n",
    "model = tf.keras.models.load_model(model_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y-Ndat25OqTk",
    "outputId": "3ab2020e-5aa7-49d1-8b15-f0479f469a0f"
   },
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fX36vsuxO7M",
    "outputId": "45f9483b-3d21-4012-a42d-234eef2e4d2d"
   },
   "source": [
    "label_mapping = {'waste': 0,\n",
    "                 'home_object': 1,\n",
    "                 'pet': 2,\n",
    "                 'person': 3,\n",
    "                 'spill': 4,\n",
    "                 'dirt': 5}\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "print(reverse_label_mapping)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "L0hFLmFU3o6F",
    "outputId": "517697f3-29d5-4186-df1f-9793b5542931"
   },
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load an image from a given path.\"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image from {path}\")\n",
    "    return image\n",
    "\n",
    "def predict_random_xml_and_image(xml_folder, image_folder, model):\n",
    "    \"\"\"\n",
    "    Selects random XML files from the xml_folder, loads corresponding images from the image_folder,\n",
    "    and makes predictions using the provided model.\n",
    "\n",
    "    Args:\n",
    "    xml_folder: Path to the folder containing XML files.\n",
    "    image_folder: Path to the folder containing image files.\n",
    "    model: Pretrained model instance.\n",
    "    \"\"\"\n",
    "    xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]\n",
    "\n",
    "    if not xml_files:\n",
    "        print(\"No XML files found in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    # Choose a random set of 8 XML files\n",
    "    random_xml_files = random.sample(xml_files, min(8, len(xml_files)))\n",
    "\n",
    "    images = []\n",
    "    predictions = []\n",
    "\n",
    "    for random_xml_file in random_xml_files:\n",
    "        base_name = os.path.splitext(random_xml_file)[0]\n",
    "        image_file = os.path.join(image_folder, base_name + '.jpg')\n",
    "\n",
    "        if not os.path.exists(image_file):\n",
    "            print(f\"Image file not found: {image_file}\")\n",
    "            continue\n",
    "\n",
    "        image = load_image(image_file)\n",
    "        images.append(image)\n",
    "\n",
    "        # Get the model prediction\n",
    "        annotated_image, prediction = _process_image(image, model)\n",
    "        predictions.append((annotated_image, prediction))\n",
    "\n",
    "    # Display images and predictions\n",
    "    display_predictions(images, predictions)\n",
    "\n",
    "def _process_image(image, model):\n",
    "    \"\"\"Process and predict on the loaded image.\"\"\"\n",
    "    image_resized = cv2.resize(image, (299, 299))\n",
    "    image_array = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "    # Get model predictions\n",
    "    categ, bbox = model.predict(image_array)\n",
    "\n",
    "    categ_index = np.argmax(categ)\n",
    "\n",
    "    # Flatten and convert bbox coordinates to integers\n",
    "    bbox = bbox.flatten().astype(int)\n",
    "\n",
    "    # Draw bounding box on a copy of the resized image\n",
    "    image_annotated = cv2.rectangle(image_resized.copy(), (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    prediction = reverse_label_mapping[categ_index]\n",
    "\n",
    "    return image_annotated, prediction\n",
    "\n",
    "def display_predictions(images, predictions):\n",
    "    \"\"\"Display images with predictions below each image in a grid.\"\"\"\n",
    "    # Create a 2x4 grid for 8 images\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Model Predictions', fontsize=16)\n",
    "\n",
    "    for i, (ax, (img, prediction)) in enumerate(zip(axs.flatten(), predictions), start=1):\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Set title with image number and prediction\n",
    "        ax.set_title(f'Image {i}: {prediction}', fontsize=12)\n",
    "\n",
    "    plt.tight_layout(pad=1.2, h_pad=1)\n",
    "    plt.subplots_adjust(top=0.9)  # Adjust title position\n",
    "    plt.show()\n",
    "\n",
    "# Define paths\n",
    "xml_folder_path = '/content/cleaning_bot_object_dataset/xmls'\n",
    "image_folder_path = '/content/cleaning_bot_object_dataset/images'\n",
    "\n",
    "# Call the prediction function with the model\n",
    "predict_random_xml_and_image(xml_folder_path, image_folder_path, model)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
