{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KTSr6KNsf1p"
   },
   "source": [
    "loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6JwgVZ_i8RtG",
    "outputId": "572c8f0b-78ee-4687-f41e-3b93e4a74150",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344376742,
     "user_tz": -330,
     "elapsed": 23442,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"LpIOo51TriziCYxqzIZw\")\n",
    "project = rf.workspace(\"test-hmoom\").project(\"cleaning_bot_dataset_2.0\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"voc\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pchPQ_91qas_"
   },
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UgCbKnEOpzEy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344387017,
     "user_tz": -330,
     "elapsed": 10271,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as et\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from tensorflow.keras.models import Model\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "import shutil\n",
    "import json\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from collections import Counter\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw2l8x0W4I_H",
    "outputId": "d3deea40-abf8-4923-ed92-dd5305222edc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344387033,
     "user_tz": -330,
     "elapsed": 35,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "def rename_folder(folder_path, new_name):\n",
    "    # Get the directory containing the folder\n",
    "    parent_dir = os.path.dirname(folder_path)\n",
    "\n",
    "    # Create the new path with the new folder name\n",
    "    new_folder_path = os.path.join(parent_dir, new_name)\n",
    "\n",
    "    # Rename the folder\n",
    "    os.rename(folder_path, new_folder_path)\n",
    "\n",
    "    print(f\"Folder renamed from {folder_path} to {new_folder_path}\")\n",
    "\n",
    "# Find all matching folders using glob function\n",
    "folder_paths = glob('/content/cleaning_bot_dataset_2.0-*')\n",
    "\n",
    "if folder_paths:\n",
    "    folder_path = folder_paths[0]  # Use the first match\n",
    "    new_folder_name = 'cleaning_bot_object_dataset'  # New folder name\n",
    "    rename_folder(folder_path, new_folder_name)\n",
    "else:\n",
    "    print(\"No matching folders found.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5VFTngnsyvD"
   },
   "source": [
    "splitting dataset into separate images and xml folders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_lNkO3mPs3OR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390139,
     "user_tz": -330,
     "elapsed": 3124,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "dc721f7a-e096-43d7-a4b1-01ea9b5196d6"
   },
   "source": [
    "def move_files_by_extension(source_directory, target_directory, file_extension):\n",
    "    # Ensure the target directory exists (create it if it doesn't)\n",
    "    os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "    # Walk through the source directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            # Check if the file has the specified extension\n",
    "            if file.endswith(file_extension):\n",
    "                # Create full path for source and destination\n",
    "                source_path = os.path.join(root, file)\n",
    "                target_path = os.path.join(target_directory, file)\n",
    "\n",
    "                # Move the file\n",
    "                shutil.move(source_path, target_path)\n",
    "                print(f\"Moved: {source_path} to {target_path}\")\n",
    "\n",
    "def organize_files(folder_name):\n",
    "    # Define source and target directories based on the folder name\n",
    "    source_directory = os.path.join(\"/content/cleaning_bot_object_dataset/\", folder_name)\n",
    "    xml_target_directory = os.path.join(source_directory, \"xmls\")\n",
    "    images_target_directory = os.path.join(source_directory, \"images\")\n",
    "\n",
    "    # Create target directories if they don't exist\n",
    "    os.makedirs(xml_target_directory, exist_ok=True)\n",
    "    os.makedirs(images_target_directory, exist_ok=True)\n",
    "\n",
    "    # Move XML files\n",
    "    move_files_by_extension(source_directory, xml_target_directory, \".xml\")\n",
    "\n",
    "    # Move JPG files\n",
    "    move_files_by_extension(source_directory, images_target_directory, \".jpg\")\n",
    "\n",
    "organize_files(\"test\")\n",
    "organize_files(\"train\")\n",
    "organize_files(\"valid\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXmLDjXkAyym"
   },
   "source": [
    "combine train, valid, test to process together and split later after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtGvXf63A4ey",
    "outputId": "8786e6ae-c150-4b44-ece9-f8146a2bfd17",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390452,
     "user_tz": -330,
     "elapsed": 307,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "# Define the source directories\n",
    "source_dirs = ['/content/cleaning_bot_object_dataset/train', '/content/cleaning_bot_object_dataset/valid', '/content/cleaning_bot_object_dataset/test']\n",
    "\n",
    "# Define the destination directory\n",
    "destination_dir = '/content/cleaning_bot_object_dataset'\n",
    "xml_dest_dir = os.path.join(destination_dir, 'xmls')\n",
    "jpg_dest_dir = os.path.join(destination_dir, 'images')\n",
    "\n",
    "# Create the destination directories if they do not exist\n",
    "os.makedirs(xml_dest_dir, exist_ok=True)\n",
    "os.makedirs(jpg_dest_dir, exist_ok=True)\n",
    "\n",
    "# Copy XML and JPG files from source directories to destination directories\n",
    "for src_dir in source_dirs:\n",
    "    xml_src_dir = os.path.join(src_dir, 'xmls')\n",
    "    jpg_src_dir = os.path.join(src_dir, 'images')\n",
    "\n",
    "    # Copy XML files\n",
    "    for filename in os.listdir(xml_src_dir):\n",
    "        src_file = os.path.join(xml_src_dir, filename)\n",
    "        dest_file = os.path.join(xml_dest_dir, filename)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "    # Copy JPG files\n",
    "    for filename in os.listdir(jpg_src_dir):\n",
    "        src_file = os.path.join(jpg_src_dir, filename)\n",
    "        dest_file = os.path.join(jpg_dest_dir, filename)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "print(\"Files have been successfully combined.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gYhPdjM3Dv5Q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390456,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "def delete_folder(folder_path):\n",
    "\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove the folder and all its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' and all its contents have been deleted.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8tdRwrkD4hE",
    "outputId": "fb2fd4a4-e767-47ca-ee2e-0837b620e78a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390487,
     "user_tz": -330,
     "elapsed": 29,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "folder_to_delete = '/content/cleaning_bot_object_dataset/train'\n",
    "delete_folder(folder_to_delete)\n",
    "\n",
    "folder_to_delete = '/content/cleaning_bot_object_dataset/valid'\n",
    "delete_folder(folder_to_delete)\n",
    "\n",
    "folder_to_delete = '/content/cleaning_bot_object_dataset/test'\n",
    "delete_folder(folder_to_delete)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORP1oOW-Ctm6",
    "outputId": "f9b6f50a-744f-453d-ea3f-273e818fbc1f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390492,
     "user_tz": -330,
     "elapsed": 7,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "def count_files_in_folder(folder_path):\n",
    "    # List all files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    return len(files)\n",
    "\n",
    "folder_path = '/content/cleaning_bot_object_dataset/xmls'\n",
    "file_count = count_files_in_folder(folder_path)\n",
    "print(f\"Number of files in '{folder_path}': {file_count}\")\n",
    "\n",
    "folder_path = '/content/cleaning_bot_object_dataset/images'\n",
    "file_count = count_files_in_folder(folder_path)\n",
    "print(f\"Number of files in '{folder_path}': {file_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zrR577EFEEv"
   },
   "source": [
    "build xml parser"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tnhpM6w4yg0q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390494,
     "user_tz": -330,
     "elapsed": 1,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "def parse_annotation(xml_file):\n",
    "    tree = et.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    annotation = {\n",
    "        'filename': root.find('filename').text,\n",
    "        'size': {\n",
    "            'width': int(root.find('size/width').text),\n",
    "            'height': int(root.find('size/height').text),\n",
    "            'depth': int(root.find('size/depth').text),\n",
    "        },\n",
    "        'objects': []\n",
    "    }\n",
    "\n",
    "    for obj in root.findall('object'):\n",
    "        obj_data = {\n",
    "            'name': obj.find('name').text,\n",
    "            'bndbox': {\n",
    "                'xmin': int(obj.find('bndbox/xmin').text),\n",
    "                'xmax': int(obj.find('bndbox/xmax').text),\n",
    "                'ymin': int(obj.find('bndbox/ymin').text),\n",
    "                'ymax': int(obj.find('bndbox/ymax').text),\n",
    "            },\n",
    "            'polygon': []\n",
    "        }\n",
    "\n",
    "        for i in range(1, 60):  # Assuming no more than 60 points in a polygon\n",
    "            x = obj.find(f'polygon/x{i}')\n",
    "            y = obj.find(f'polygon/y{i}')\n",
    "            if x is not None and y is not None:\n",
    "                obj_data['polygon'].append((float(x.text), float(y.text)))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        annotation['objects'].append(obj_data)\n",
    "\n",
    "    return annotation\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xrte2xf8r317",
    "outputId": "ed206c19-d1a4-4023-aa05-2a5905d66e1f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390501,
     "user_tz": -330,
     "elapsed": 6,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "# Specify the folder path\n",
    "folder_path = '/content/cleaning_bot_object_dataset/xmls'\n",
    "\n",
    "# Get a list of files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Choose a random file\n",
    "random_file = random.choice(files)\n",
    "\n",
    "# Get the full path of the chosen file\n",
    "xml_file = os.path.join(folder_path, random_file)\n",
    "# xml_file = '/content/cleaning_bot_object_dataset/xmls/standing_8_11_23-71-_jpg.rf.ee430e8bb392e115f304698468892cad.xml'\n",
    "\n",
    "parsed_data = parse_annotation(xml_file)\n",
    "\n",
    "# Pretty-print the parsed data\n",
    "print(json.dumps(parsed_data, indent=4))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8gadr_Yy8Ij"
   },
   "source": [
    "find data distribution by parsing xmls"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-D4PnIKy_Kf",
    "outputId": "ae24b6c6-7319-4f1c-e78a-4616d17ba77c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390505,
     "user_tz": -330,
     "elapsed": 3,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "def parse_annotations_for_classes(xml_folder):\n",
    "    \"\"\"\n",
    "    Parses annotation XML files and extracts labels.\n",
    "\n",
    "    Args:\n",
    "    xml_folder: Path to the folder containing XML files\n",
    "\n",
    "    Returns:\n",
    "    A list of labels extracted from the XML files\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "\n",
    "    for xml_file in os.listdir(xml_folder):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            tree = et.parse(os.path.join(xml_folder, xml_file))\n",
    "            root = tree.getroot()\n",
    "\n",
    "            for obj in root.findall('object'):\n",
    "                label = obj.find('name').text\n",
    "                # Filter out any non-relevant labels (e.g., if label is not empty)\n",
    "                if label.strip():  # Make sure it's not an empty string or just whitespace\n",
    "                    labels.append(label)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def count_labels(labels):\n",
    "    \"\"\"\n",
    "    Counts occurrences of each label.\n",
    "\n",
    "    Args:\n",
    "    labels: A list of labels\n",
    "\n",
    "    Returns:\n",
    "    A pandas DataFrame with counts of each label\n",
    "    \"\"\"\n",
    "    label_counts = Counter(labels)\n",
    "    label_df = pd.DataFrame(label_counts.items(), columns=['Label', 'Count'])\n",
    "    label_df = label_df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    return label_df\n",
    "\n",
    "# Define paths\n",
    "xml_folder_path = '/content/cleaning_bot_object_dataset/xmls'\n",
    "\n",
    "# Parse annotations and count labels\n",
    "labels = parse_annotations_for_classes(xml_folder_path)\n",
    "label_distribution = count_labels(labels)\n",
    "\n",
    "# Print the output\n",
    "print(label_distribution)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yiRO2fNtcCnN",
    "outputId": "6d881ff9-9b03-4fc7-f012-9f895d5a0e89",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390510,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "# label_mapping = {\n",
    "#     'clothes': 0,\n",
    "#     'dust_debris': 1,\n",
    "#     'electronics': 2,\n",
    "#     'furniture': 3,\n",
    "#     'household_item': 4,\n",
    "#     'liquid_spill': 5,\n",
    "#     'person': 6,\n",
    "#     'pet': 7,\n",
    "#     'small_objects': 8,\n",
    "#     'waste': 9\n",
    "# }\n",
    "\n",
    "# define label mapping\n",
    "label_mapping = {label: idx for idx, label in enumerate(label_distribution['Label'].unique())}\n",
    "\n",
    "num_classes = len(label_mapping)\n",
    "print('total classes = ', num_classes)\n",
    "# label_mapping['null'] = total_classes + 1\n",
    "print(label_mapping)\n",
    "\n",
    "# Reverse the label_mapping dictionary to map numbers to names\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuqvJazdFa1C"
   },
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0bYGOeLFQmm"
   },
   "source": [
    "create list of all parsed xml annotation data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KC9hMCO06BAC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390515,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "859a359a-c2b3-428a-fe6c-8c90a3293318"
   },
   "source": [
    "# Get all XML file paths\n",
    "xml_files = sorted(glob('/content/cleaning_bot_object_dataset/xmls/*.xml'))\n",
    "image_folder = '/content/cleaning_bot_object_dataset/images/'  # Path to the images folder\n",
    "\n",
    "y = []  # List to store the targets\n",
    "\n",
    "# Loop over each file path and parse it\n",
    "for xml_file in xml_files:\n",
    "    tree = et.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the object element\n",
    "    obj = root.find('object')\n",
    "\n",
    "    if obj is not None:\n",
    "        label_obj = obj.find('name').text\n",
    "\n",
    "        # Get label from the mapping\n",
    "        label = label_mapping.get(label_obj)\n",
    "\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "        # Append the results to our target list\n",
    "        y.append([label, xmin, ymin, xmax, ymax])\n",
    "    else:\n",
    "        # Determine the corresponding image file (same name as XML file, but with .jpg extension)\n",
    "        base_name = os.path.basename(xml_file).replace('.xml', '')\n",
    "        image_file = os.path.join(image_folder, f\"{base_name}.jpg\")\n",
    "\n",
    "        # Delete both the XML and the corresponding image file\n",
    "        if os.path.exists(xml_file):\n",
    "            os.remove(xml_file)\n",
    "            print(f\"Deleted XML: {xml_file}\")\n",
    "        if os.path.exists(image_file):\n",
    "            os.remove(image_file)\n",
    "            print(f\"Deleted Image: {image_file}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(y[random.randint(0, file_count)])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBuP6IsLpRsj",
    "outputId": "4cd8f896-54a0-49b3-ce8c-9b7095fdf6e8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344390519,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj5tl7D_FWR7"
   },
   "source": [
    "create list of all images associated to xml files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jHIa8j2s57DN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344391978,
     "user_tz": -330,
     "elapsed": 1458,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "x = []  # List to store the images\n",
    "\n",
    "# Get all image paths\n",
    "images_path = sorted(glob('/content/cleaning_bot_object_dataset/images/*.jpg'))\n",
    "\n",
    "# Loop over image paths\n",
    "for image_path in images_path:\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    x.append(img_rgb)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "CfeiIZ9N__M7",
    "outputId": "6c98f2f4-b1d5-4d25-816e-4ebfbf2efdd2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344392724,
     "user_tz": -330,
     "elapsed": 748,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "# Ensure file_count is the length of x\n",
    "file_count = len(x)\n",
    "\n",
    "# Extract random image and the corresponding bounding box coordinates\n",
    "num = random.randint(0, file_count - 1)  # Adjusted to prevent out-of-bounds error\n",
    "img_example = x[num]\n",
    "bbox = y[num][1:]  # Bounding box coordinates from the first annotation\n",
    "label = y[num][0]  # The label of the image\n",
    "label_name = reverse_label_mapping[label]\n",
    "\n",
    "def visualize_image_with_bbox(img, bbox, label, label_name):\n",
    "    # Draw the bounding box on the image\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "    cv2.putText(img, 'Label: {}'.format(label_name), (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Print raw data for inspection\n",
    "    print(f\"Raw image array shape: {img.shape}\")\n",
    "    print(f\"Bounding box coordinates: {bbox}\")\n",
    "    print(f\"Label: {label} ({label_name})\")\n",
    "    print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "# Visualize the image with the bounding box\n",
    "visualize_image_with_bbox(img_example, bbox, label, label_name)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDvsVpBjFjlD"
   },
   "source": [
    "split into train, test numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLU_GsRcE6FN",
    "outputId": "a05dde40-e781-4218-a9d7-50f3a9b4de94",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344393539,
     "user_tz": -330,
     "elapsed": 814,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "source": [
    "# Convert lists to NumPy arrays\n",
    "x = np.array(x)  # Convert list of images to numpy array\n",
    "y = np.array(y)  # Convert list of labels to numpy array\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=21)\n",
    "\n",
    "# Check the shapes of the split data\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Assuming y is structured as [label, xmin, ymin, xmax, ymax]\n",
    "labels = [entry[0] for entry in y]  # Extracting only the class labels\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "print(\"Label counts:\", label_counts)\n",
    "print(\"Total samples in y:\", len(y))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whR7eCEMlGGh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344393557,
     "user_tz": -330,
     "elapsed": 16,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "6fb821dd-3fc7-4f13-807a-ae1f94d828e0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPn8sia4I2jn"
   },
   "source": [
    "split data into separate categorical and boundary box sectors"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "categ_train = y_train[:, 0]  # Take the first column for training categories\n",
    "categ_test = y_test[:, 0]    # Take the first column for testing categories\n",
    "bbox_train = y_train[:, 1:]   # Take the remaining columns for training bounding boxes\n",
    "bbox_test = y_test[:, 1:]     # Take the remaining columns for testing bounding boxes\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"categ_train shape: {categ_train.shape}\")\n",
    "print(f\"categ_test shape: {categ_test.shape}\")\n",
    "print(f\"bbox_train shape: {bbox_train.shape}\")\n",
    "print(f\"bbox_test shape: {bbox_test.shape}\")\n",
    "\n",
    "# Convert category labels to one-hot encoded vectors\n",
    "categ_train = tf.keras.utils.to_categorical(categ_train.astype(int), num_classes=num_classes)\n",
    "categ_test = tf.keras.utils.to_categorical(categ_test.astype(int), num_classes=num_classes)\n",
    "\n",
    "# Print shapes after one-hot encoding\n",
    "print(f\"One-hot encoded categ_train shape: {categ_train.shape}\")\n",
    "print(f\"One-hot encoded categ_test shape: {categ_test.shape}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwD8ik90kgmF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344393614,
     "user_tz": -330,
     "elapsed": 56,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "6d461963-b783-4048-b952-cb79e4584c43"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUxfTRfOJXPi"
   },
   "source": [
    "Loading the Inception V3 model with custom layers\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "input_shape = (299, 299, 3)\n",
    "learning_rate_initial = 1e-4  # Initial learning rate\n",
    "\n",
    "# Load InceptionV3 with pre-trained ImageNet weights, excluding the top layers\n",
    "inception = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Get the output of the 'mixed10' layer\n",
    "last_layer = inception.get_layer('mixed10').output\n",
    "\n",
    "# Add custom layers\n",
    "x = Flatten()(last_layer)  # Flatten the output from 'mixed10'\n",
    "x = Dropout(0.2)(x)  # Regularization to reduce overfitting\n",
    "x = Dense(512, activation=\"relu\")(x)  # Dense layer with ReLU activation\n",
    "x = Dropout(0.2)(x)  # Another Dropout layer\n",
    "\n",
    "# Output layers: Classification and Bounding Box Regression\n",
    "classification_output = Dense(num_classes, activation='softmax', name='classification')(x)\n",
    "bounding_box_output = Dense(4, activation='linear', name='bounding_box')(x)\n",
    "\n",
    "# Create the final model with InceptionV3 inputs and two outputs\n",
    "model = Model(inputs=inception.inputs, outputs=[classification_output, bounding_box_output])\n",
    "\n",
    "# Compile the model with optimizer, losses, and metrics\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_initial),\n",
    "    loss={\n",
    "        'classification': 'categorical_crossentropy',  # Classification task\n",
    "        'bounding_box': 'mse'  # Bounding box regression task\n",
    "    },\n",
    "    metrics={\n",
    "        'classification': 'accuracy',  # Track classification accuracy\n",
    "        'bounding_box': 'mse'  # Track Mean Squared Error for bounding boxes\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n",
    "\n",
    "# Define the learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 42:\n",
    "        return float(lr)  # Keep learning rate constant for first 42 epochs\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.12))  # Exponential decay of learning rate\n",
    "\n",
    "# Define callbacks\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)  # Learning rate scheduler\n",
    "\n",
    "# Specify the path where you want to save the model\n",
    "checkpoint_path = '/content/models/best_model.keras'\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',  # or 'val_accuracy' depending on your metric of interest\n",
    "    save_best_only=True,\n",
    "    mode='min',  # or 'max' if you're monitoring accuracy\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "# TensorBoard for visualization\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./logs')  # Logs for TensorBoard visualization\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9keCeQoQK77J",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745344402025,
     "user_tz": -330,
     "elapsed": 8409,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "833ac4dc-c3e5-4915-e71c-47c7fcab2281"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBgyoga1qQiN"
   },
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "r = model.fit(\n",
    "    x_train,  # Training images\n",
    "    [categ_train, bbox_train],  # Classification and bounding box labels\n",
    "    epochs=100,  # Number of epochs\n",
    "    batch_size=32,  # Batch size\n",
    "    validation_data=(x_test, [categ_test, bbox_test]),  # Validation data\n",
    "    callbacks=[callback_lr, checkpoint_callback, early_stopping, tensorboard],  # Callbacks for dynamic LR, saving, early stopping, and TensorBoard\n",
    "    verbose=1  # Show training progress\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQ-VG-0uLRqe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346270708,
     "user_tz": -330,
     "elapsed": 1868682,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "dfe2ddb4-3406-4348-b287-d646f5540284"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fWk10siMbDC9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346270809,
     "user_tz": -330,
     "elapsed": 99,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "5adc2cfa-6c71-46ee-a75a-2c10e4c07cc8"
   },
   "source": [
    "results = pd.DataFrame(r.history)\n",
    "results.tail()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results.columns"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VOjcUiF1bzp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346270820,
     "user_tz": -330,
     "elapsed": 11,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "e2570cf1-caca-42b4-c2f4-6b6f3053752c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the results DataFrame as an Excel file\n",
    "results.to_excel(\"model_results.xlsx\", index=False)"
   ],
   "metadata": {
    "id": "ppfcx4Sp1WDQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346271115,
     "user_tz": -330,
     "elapsed": 294,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the results DataFrame from an Excel file\n",
    "file_path = '/content/model_results.xlsx'  # Change this to your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create an 'epoch' column starting from 1\n",
    "df['epoch'] = df.index + 1  # Adding 1 to start epochs from 1\n",
    "\n",
    "# Select rows for every 5 epochs\n",
    "milestone_epochs = df.iloc[::5]  # Every 5th row (which corresponds to every 5th epoch)\n",
    "\n",
    "# Display the selected milestone epochs\n",
    "print(milestone_epochs)\n",
    "\n",
    "# If you want to save this to a new Excel file\n",
    "milestone_epochs.to_excel('milestone_epochs.xlsx', index=False)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwUugOa7-sBV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346271264,
     "user_tz": -330,
     "elapsed": 140,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "fb5b96e1-e156-45e0-80df-cd8cb0ec7b50"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7rok42Bcs18"
   },
   "source": [
    "Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./logs"
   ],
   "metadata": {
    "id": "HM_P0HRgM7kF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346271266,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the data from the Excel file\n",
    "file_path = '/content/model_results.xlsx'  # Update with your file path\n",
    "results = pd.read_excel(file_path)\n",
    "\n",
    "# Smoothing function (moving average)\n",
    "def smooth(series, window_size=5):\n",
    "    return series.rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "# Add smoothed columns to the results dataframe\n",
    "results['smooth_classification_accuracy'] = smooth(results['classification_accuracy'])\n",
    "results['smooth_val_classification_accuracy'] = smooth(results['val_classification_accuracy'])\n",
    "results['smooth_bounding_box_mse'] = smooth(results['bounding_box_mse'])\n",
    "results['smooth_val_bounding_box_mse'] = smooth(results['val_bounding_box_mse'])\n",
    "\n",
    "# Create a figure with 2 rows and 2 columns for subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))  # 2x2 grid of plots\n",
    "\n",
    "# Define a function to add a border to the subplots\n",
    "def add_border(ax):\n",
    "    ax.patch.set_edgecolor('black')\n",
    "    ax.patch.set_linewidth(2)\n",
    "\n",
    "# 1. Smoothed Classification Accuracy\n",
    "axes[0, 0].plot(results['smooth_classification_accuracy'], label='Smoothed Training Accuracy', color='#8B0000', linewidth=2)\n",
    "axes[0, 0].plot(results['smooth_val_classification_accuracy'], label='Smoothed Validation Accuracy', color='#006400', linewidth=2)\n",
    "axes[0, 0].set_title('Smoothed Classification Accuracy Over Epochs', fontsize=16, fontweight='bold', fontname='DejaVu Serif')\n",
    "axes[0, 0].set_xlabel('Epochs', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[0, 0].legend(loc='best', fontsize=12)\n",
    "axes[0, 0].grid(True)\n",
    "add_border(axes[0, 0])\n",
    "axes[0, 0].text(0.5, -0.2, 'Plot 1', ha='center', va='center', fontsize=12, fontweight='bold', transform=axes[0, 0].transAxes)\n",
    "\n",
    "# 2. Smoothed Bounding Box Loss\n",
    "axes[0, 1].plot(results['smooth_bounding_box_mse'], label='Smoothed Training Loss', color='#8B0000', linewidth=2)\n",
    "axes[0, 1].plot(results['smooth_val_bounding_box_mse'], label='Smoothed Validation Loss', color='#006400', linewidth=2)\n",
    "axes[0, 1].set_title('Smoothed Bounding Box Loss Over Epochs', fontsize=16, fontweight='bold', fontname='DejaVu Serif')\n",
    "axes[0, 1].set_xlabel('Epochs', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[0, 1].set_ylabel('Bounding Box MSE', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[0, 1].legend(loc='best', fontsize=12)\n",
    "axes[0, 1].grid(True)\n",
    "add_border(axes[0, 1])\n",
    "axes[0, 1].text(0.5, -0.2, 'Plot 2', ha='center', va='center', fontsize=12, fontweight='bold', transform=axes[0, 1].transAxes)\n",
    "\n",
    "# 3. Combined Loss\n",
    "axes[1, 0].plot(results['loss'], label='Training Loss', color='#8B0000', linewidth=2)\n",
    "axes[1, 0].plot(results['val_loss'], label='Validation Loss', color='#006400', linewidth=2)\n",
    "axes[1, 0].set_title('Combined Loss Over Epochs', fontsize=16, fontweight='bold', fontname='DejaVu Serif')\n",
    "axes[1, 0].set_xlabel('Epochs', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[1, 0].set_ylabel('Loss', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[1, 0].legend(loc='best', fontsize=12)\n",
    "axes[1, 0].grid(True)\n",
    "add_border(axes[1, 0])\n",
    "axes[1, 0].text(0.5, -0.2, 'Plot 3', ha='center', va='center', fontsize=12, fontweight='bold', transform=axes[1, 0].transAxes)\n",
    "\n",
    "# 4. Training vs Validation Accuracy\n",
    "axes[1, 1].plot(results['classification_accuracy'], label='Training Accuracy', color='#8B0000', linewidth=2)\n",
    "axes[1, 1].plot(results['val_classification_accuracy'], label='Validation Accuracy', color='#006400', linewidth=2)\n",
    "axes[1, 1].set_title('Training vs Validation Accuracy Over Epochs', fontsize=16, fontweight='bold', fontname='DejaVu Serif')\n",
    "axes[1, 1].set_xlabel('Epochs', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[1, 1].set_ylabel('Accuracy', fontsize=14, fontname='DejaVu Serif')\n",
    "axes[1, 1].legend(loc='best', fontsize=12)\n",
    "axes[1, 1].grid(True)\n",
    "add_border(axes[1, 1])\n",
    "axes[1, 1].text(0.5, -0.2, 'Plot 4', ha='center', va='center', fontsize=12, fontweight='bold', transform=axes[1, 1].transAxes)\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the entire figure\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "id": "MqrTSc4tq1Zk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346272309,
     "user_tz": -330,
     "elapsed": 1044,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "dab46d9e-3de5-4dac-c352-43302759c95e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Smoothing function (moving average)\n",
    "def smooth(series, window_size=5):\n",
    "    return series.rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "# Add smoothed columns to the results dataframe\n",
    "results['smooth_classification_accuracy'] = smooth(results['classification_accuracy'])\n",
    "results['smooth_val_classification_accuracy'] = smooth(results['val_classification_accuracy'])\n",
    "results['smooth_bounding_box_mse'] = smooth(results['bounding_box_mse'])\n",
    "results['smooth_val_bounding_box_mse'] = smooth(results['val_bounding_box_mse'])\n",
    "\n",
    "# Function to plot with borders, consistent style, and formatting\n",
    "def plot_metric(results, y_values, title, y_label, colors=['#8B0000', '#006400']):  # Dark Red and Dark Green\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot each value with the provided colors\n",
    "    for i, y in enumerate(y_values):\n",
    "        plt.plot(results[y], label=y.replace('_', ' ').title(), color=colors[i], linewidth=2)\n",
    "\n",
    "    # Add title, labels, and grid\n",
    "    plt.title(title, fontsize=16, fontweight='bold', fontname='DejaVu Serif')\n",
    "    plt.xlabel('Epochs', fontsize=14, fontname='DejaVu Serif')\n",
    "    plt.ylabel(y_label, fontsize=14, fontname='DejaVu Serif')\n",
    "\n",
    "    # Set tick labels font\n",
    "    plt.xticks(fontsize=12, fontname='DejaVu Serif')\n",
    "    plt.yticks(fontsize=12, fontname='DejaVu Serif')\n",
    "\n",
    "    # Add a legend with the best location\n",
    "    plt.legend(loc='best', fontsize=12)\n",
    "\n",
    "    # Add a grid for clarity\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Add a rectangle border around the whole plot (including labels and title)\n",
    "    plt.gca().patch.set_edgecolor('black')\n",
    "    plt.gca().patch.set_linewidth(2)\n",
    "\n",
    "    # Set white background\n",
    "    plt.gca().set_facecolor('white')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Smoothed Classification Accuracy\n",
    "plot_metric(results,\n",
    "            ['smooth_classification_accuracy', 'smooth_val_classification_accuracy'],\n",
    "            'Smoothed Classification Accuracy Over Epochs',\n",
    "            'Smoothed Accuracy')\n",
    "\n",
    "# Smoothed Bounding Box Loss\n",
    "plot_metric(results,\n",
    "            ['smooth_bounding_box_mse', 'smooth_val_bounding_box_mse'],\n",
    "            'Smoothed Bounding Box Loss Over Epochs',\n",
    "            'Smoothed Bounding Box MSE')\n",
    "\n",
    "# Combined Loss Over Epochs (no smoothing needed)\n",
    "plot_metric(results,\n",
    "            ['loss', 'val_loss'],\n",
    "            'Combined Loss Over Epochs',\n",
    "            'Loss')\n",
    "\n",
    "# Training vs Validation Accuracy (unsmoothed)\n",
    "plot_metric(results,\n",
    "            ['classification_accuracy', 'val_classification_accuracy'],\n",
    "            'Training vs Validation Accuracy Over Epochs',\n",
    "            'Accuracy')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1g9o0GFJoi1U",
    "outputId": "6547bdc7-dfa5-4036-d8c1-8a260ffe771c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346272772,
     "user_tz": -330,
     "elapsed": 467,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the results DataFrame from an Excel file\n",
    "file_path = '/content/model_results.xlsx'  # Change this to your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand its structure\n",
    "print(df.columns)\n",
    "\n",
    "# Create an 'epoch' column starting from 1\n",
    "df['epoch'] = df.index + 1  # Adding 1 to start epochs from 1\n",
    "\n",
    "# Select rows for every 5 epochs\n",
    "milestone_epochs = df.iloc[::5]  # Every 5th row (which corresponds to every 5th epoch)\n",
    "\n",
    "# Display the selected milestone epochs\n",
    "print(milestone_epochs)\n",
    "\n",
    "# If you want to save this to a new Excel file\n",
    "milestone_epochs.to_excel('milestone_epochs.xlsx', index=False)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEb5jNdzKy1K",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346272775,
     "user_tz": -330,
     "elapsed": 16,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "02e08c08-694e-435b-b4dd-4cf1211540c0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX8WuD-WjYpN"
   },
   "source": [
    "testing the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_path = '/content/models/best_model.keras'\n",
    "model = tf.keras.models.load_model(model_path)"
   ],
   "metadata": {
    "id": "acfyjzDqa_et",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346619329,
     "user_tz": -330,
     "elapsed": 5757,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load an image from a given path.\"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image from {path}\")\n",
    "    return image\n",
    "\n",
    "def predict_random_xml_and_image(xml_folder, image_folder, model):\n",
    "    \"\"\"\n",
    "    Selects a random XML file from the xml_folder, loads the corresponding image from the image_folder,\n",
    "    and makes predictions using the provided model.\n",
    "\n",
    "    Args:\n",
    "    xml_folder: Path to the folder containing XML files.\n",
    "    image_folder: Path to the folder containing image files.\n",
    "    model: Pretrained model instance.\n",
    "    \"\"\"\n",
    "    # Get a list of XML files in the folder\n",
    "    xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]\n",
    "\n",
    "    # Check if there are any XML files\n",
    "    if not xml_files:\n",
    "        print(\"No XML files found in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    # Choose a random XML file\n",
    "    random_xml_file = random.choice(xml_files)\n",
    "\n",
    "    # Get the corresponding image file name\n",
    "    base_name = os.path.splitext(random_xml_file)[0]\n",
    "    image_file = os.path.join(image_folder, base_name + '.jpg')  # Change '.jpg' to the correct image extension if needed\n",
    "\n",
    "    # Check if the image file exists\n",
    "    if not os.path.exists(image_file):\n",
    "        print(f\"Image file not found: {image_file}\")\n",
    "        return\n",
    "\n",
    "    # Load the corresponding image\n",
    "    image = load_image(image_file)\n",
    "\n",
    "    # Proceed with predictions\n",
    "    _process_image(image, model)\n",
    "\n",
    "def _process_image(image, model):\n",
    "    \"\"\"Process and predict on the loaded image.\"\"\"\n",
    "    # Resize the image to match model input shape\n",
    "    image_resized = cv2.resize(image, (299, 299))\n",
    "    image_array = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "    # Get model predictions\n",
    "    categ, bbox = model.predict(image_array)\n",
    "\n",
    "    # Print raw predictions for debugging\n",
    "    print(\"Raw category predictions:\", categ)\n",
    "    print(\"Raw bounding box predictions:\", bbox)\n",
    "\n",
    "    # Get class with the highest probability\n",
    "    categ_index = np.argmax(categ)\n",
    "    print(\"Predicted class index:\", categ_index)\n",
    "    print(\"Predicted class:\", reverse_label_mapping[categ_index])\n",
    "\n",
    "    # Flatten and convert bbox coordinates to integers\n",
    "    bbox = bbox.flatten().astype(int)\n",
    "    print(\"Predicted bounding box coordinates:\", bbox)\n",
    "\n",
    "    # Draw bounding box and prediction\n",
    "    image_annotated = cv2.rectangle(image_resized.copy(), (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)\n",
    "    prediction = reverse_label_mapping[categ_index]\n",
    "    final_img = cv2.putText(image_annotated, prediction, (bbox[0], bbox[1]-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Display original and annotated images side by side\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Annotated Image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Annotated Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "id": "iPFqZYRi_mMk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346619341,
     "user_tz": -330,
     "elapsed": 13,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "xml_folder_path = '/content/cleaning_bot_object_dataset/xmls'\n",
    "image_folder_path = '/content/cleaning_bot_object_dataset/images'\n",
    "\n",
    "predict_random_xml_and_image(xml_folder_path, image_folder_path, model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "id": "CR5rvK9V_rH9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346630555,
     "user_tz": -330,
     "elapsed": 11213,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "a4d2f240-2a38-4ca7-ac85-7d93b3774501"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load an image from a given path.\"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image from {path}\")\n",
    "    return image\n",
    "\n",
    "def predict_random_xml_and_image(xml_folder, image_folder, model):\n",
    "    \"\"\"\n",
    "    Selects random XML files from the xml_folder, loads corresponding images from the image_folder,\n",
    "    and makes predictions using the provided model.\n",
    "\n",
    "    Args:\n",
    "    xml_folder: Path to the folder containing XML files.\n",
    "    image_folder: Path to the folder containing image files.\n",
    "    model: Pretrained model instance.\n",
    "    \"\"\"\n",
    "    xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]\n",
    "\n",
    "    if not xml_files:\n",
    "        print(\"No XML files found in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    # Choose a random set of 8 XML files\n",
    "    random_xml_files = random.sample(xml_files, min(8, len(xml_files)))\n",
    "\n",
    "    images = []\n",
    "    predictions = []\n",
    "\n",
    "    for random_xml_file in random_xml_files:\n",
    "        base_name = os.path.splitext(random_xml_file)[0]\n",
    "        image_file = os.path.join(image_folder, base_name + '.jpg')\n",
    "\n",
    "        if not os.path.exists(image_file):\n",
    "            print(f\"Image file not found: {image_file}\")\n",
    "            continue\n",
    "\n",
    "        image = load_image(image_file)\n",
    "        images.append(image)\n",
    "\n",
    "        # Get the model prediction\n",
    "        annotated_image, prediction = _process_image(image, model)\n",
    "        predictions.append((annotated_image, prediction))\n",
    "\n",
    "    # Display images and predictions\n",
    "    display_predictions(images, predictions)\n",
    "\n",
    "def _process_image(image, model):\n",
    "    \"\"\"Process and predict on the loaded image.\"\"\"\n",
    "    image_resized = cv2.resize(image, (299, 299))\n",
    "    image_array = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "    # Get model predictions\n",
    "    categ, bbox = model.predict(image_array)\n",
    "\n",
    "    categ_index = np.argmax(categ)\n",
    "\n",
    "    # Flatten and convert bbox coordinates to integers\n",
    "    bbox = bbox.flatten().astype(int)\n",
    "\n",
    "    # Draw bounding box on a copy of the resized image\n",
    "    image_annotated = cv2.rectangle(image_resized.copy(), (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    prediction = reverse_label_mapping[categ_index]\n",
    "\n",
    "    return image_annotated, prediction\n",
    "\n",
    "def display_predictions(images, predictions):\n",
    "    \"\"\"Display images with predictions below each image in a grid.\"\"\"\n",
    "    # Create a 2x4 grid for 8 images\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Model Predictions', fontsize=16)\n",
    "\n",
    "    for i, (ax, (img, prediction)) in enumerate(zip(axs.flatten(), predictions), start=1):\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Set title with image number and prediction\n",
    "        ax.set_title(f'Image {i}: {prediction}', fontsize=12)\n",
    "\n",
    "    plt.tight_layout(pad=1.2, h_pad=1)\n",
    "    plt.subplots_adjust(top=0.9)  # Adjust title position\n",
    "    plt.show()\n",
    "\n",
    "# Define paths\n",
    "xml_folder_path = '/content/cleaning_bot_object_dataset/xmls'\n",
    "image_folder_path = '/content/cleaning_bot_object_dataset/images'\n",
    "\n",
    "# Call the prediction function with the model\n",
    "predict_random_xml_and_image(xml_folder_path, image_folder_path, model)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "44XvP7NVwdt9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745346676747,
     "user_tz": -330,
     "elapsed": 2627,
     "user": {
      "displayName": "Mr.ExplicitlyImplicit",
      "userId": "15409741418138165609"
     }
    },
    "outputId": "fce131cf-5c07-43fa-bbeb-edb505d4ef12"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1bVwBepob0_vSJzYWlssBZhupQNJlF4LP",
     "timestamp": 1745321196456
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
